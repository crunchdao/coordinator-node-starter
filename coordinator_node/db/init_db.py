from __future__ import annotations

import json
import os
from pathlib import Path
from typing import Any

from sqlalchemy import text
from sqlmodel import SQLModel, delete

from coordinator_node.db.tables import PredictionConfigRow
from coordinator_node.schemas import ScheduledPredictionConfigEnvelope
from coordinator_node.db.session import create_session, engine

MINUTE = 60


def tables_to_reset() -> list[str]:
    return [
        "merkle_nodes",
        "merkle_cycles",
        "backfill_jobs",
        "checkpoints",
        "snapshots",
        "scores",
        "predictions",
        "inputs",
        "leaderboards",
        "feed_records",
        "feed_ingestion_state",
        "scheduled_prediction_configs",
        "models",
        "alembic_version",
    ]


def default_scheduled_prediction_configs() -> list[dict[str, Any]]:
    # Starter profile: generic scope + schedule for quick local end-to-end feedback.
    return [
        {
            "scope_key": "BTC-60-60",
            "scope_template": {"asset": "BTC", "horizon": 1 * MINUTE, "step": 1 * MINUTE},
            "schedule": {
                "prediction_interval_seconds": 1 * MINUTE,
                "resolve_after_seconds": 1 * MINUTE,
            },
            "active": True,
            "order": 1,
        },
    ]


def load_scheduled_prediction_configs() -> list[dict[str, Any]]:
    path = os.getenv("SCHEDULED_PREDICTION_CONFIGS_PATH")
    if not path:
        return default_scheduled_prediction_configs()

    payload = json.loads(Path(path).read_text(encoding="utf-8"))
    if not isinstance(payload, list):
        raise ValueError("SCHEDULED_PREDICTION_CONFIGS_PATH must point to a JSON array")
    return payload


# ---------------------------------------------------------------------------
# Alembic migrations directory resolution
# ---------------------------------------------------------------------------

def _find_alembic_dir() -> Path | None:
    """Locate the Alembic migrations directory.

    Checks (in order):
      1. ``ALEMBIC_DIR`` env var (explicit override)
      2. Repo-root layout: ``<repo>/coordinator_node/db/init_db.py`` → ``<repo>/alembic/``
      3. Inside the package: ``coordinator_node/alembic/`` (if bundled in wheel)

    Returns ``None`` when no valid migrations directory is found (e.g. when
    ``coordinator-node`` is pip-installed and the ``alembic/`` directory was
    not included in the wheel).  Callers should fall back to
    ``SQLModel.metadata.create_all()`` in that case.
    """
    def _is_valid(p: Path) -> bool:
        return p.is_dir() and (p / "env.py").exists() and (p / "versions").is_dir()

    # 1. Explicit env var
    env_dir = os.getenv("ALEMBIC_DIR")
    if env_dir:
        p = Path(env_dir)
        if _is_valid(p):
            return p

    # 2. Repo-root layout (3 levels up from this file)
    repo_dir = Path(__file__).resolve().parent.parent.parent / "alembic"
    if _is_valid(repo_dir):
        return repo_dir

    # 3. Inside the package (coordinator_node/alembic/)
    pkg_dir = Path(__file__).resolve().parent.parent / "alembic"
    if _is_valid(pkg_dir):
        return pkg_dir

    return None


def _run_alembic_upgrade(alembic_dir: Path | None = None) -> None:
    """Run Alembic migrations programmatically.

    Sets a lock_timeout so DDL that needs AccessExclusiveLock won't hang
    indefinitely if another session holds a conflicting lock.

    Raises ``FileNotFoundError`` when no migrations directory is available.
    """
    if alembic_dir is None:
        alembic_dir = _find_alembic_dir()
    if alembic_dir is None:
        raise FileNotFoundError(
            "Alembic migrations directory not found. "
            "Set ALEMBIC_DIR or ensure the alembic/ directory is alongside the package."
        )

    from alembic.config import Config
    from alembic import command

    # Set a lock timeout so ALTER TABLE won't block forever on concurrent reads
    with engine.connect() as conn:
        conn.execute(text("SET lock_timeout = '30s'"))
        conn.commit()

    alembic_cfg = Config()
    alembic_cfg.set_main_option("script_location", str(alembic_dir))
    alembic_cfg.set_main_option("sqlalchemy.url", str(engine.url))
    command.upgrade(alembic_cfg, "head")


def migrate() -> None:
    """Run Alembic migrations and upsert prediction configs.
    Safe to run on every boot — never drops data."""
    alembic_dir = _find_alembic_dir()
    if alembic_dir is not None:
        print(f"➡️  Running Alembic migrations from {alembic_dir} ...")
        try:
            _run_alembic_upgrade(alembic_dir)
        except Exception as exc:
            print(f"⚠️  Alembic migration failed ({exc}), falling back to create_all...")
            SQLModel.metadata.create_all(engine)
    else:
        print("➡️  No Alembic migrations directory found, using SQLModel create_all...")
        SQLModel.metadata.create_all(engine)

    print("➡️  Upserting scheduled prediction configs...")
    with create_session() as session:
        # Drop FK temporarily so we can replace prediction configs
        session.exec(text(
            "ALTER TABLE predictions DROP CONSTRAINT IF EXISTS predictions_prediction_config_id_fkey"
        ))
        session.exec(delete(PredictionConfigRow))
        for idx, config in enumerate(load_scheduled_prediction_configs(), start=1):
            envelope = ScheduledPredictionConfigEnvelope.model_validate(config)
            session.add(
                PredictionConfigRow(
                    id=f"CFG_{idx:03d}",
                    scope_key=envelope.scope_key,
                    scope_template_jsonb=envelope.scope_template,
                    schedule_jsonb=envelope.schedule.model_dump(),
                    active=envelope.active,
                    order=envelope.order,
                    meta_jsonb=envelope.meta,
                )
            )
        session.commit()

    print("✅ Database migration complete.")


def reset_db() -> None:
    """Drop all tables and recreate from scratch. Destroys all data."""
    print("⚠️  Dropping all tables...")
    with engine.begin() as conn:
        for table in tables_to_reset():
            conn.execute(text(f"DROP TABLE IF EXISTS {table} CASCADE"))

    migrate()
    print("✅ Database reset complete.")


# Keep backward compat
init_db = reset_db


def _stamp_alembic_if_needed() -> None:
    """Stamp the DB at revision 001 if tables exist but alembic_version doesn't.

    This handles databases created by the old ``create_all`` code path before
    Alembic was introduced.  Without the stamp, ``alembic upgrade head`` tries
    to re-create every table and fails.
    """
    alembic_dir = _find_alembic_dir()
    if alembic_dir is None:
        return  # No migrations available — nothing to stamp

    from alembic.config import Config
    from alembic import command

    from sqlalchemy import inspect as sa_inspect
    inspector = sa_inspect(engine)
    if inspector.has_table("models") and not inspector.has_table("alembic_version"):
        print("➡️  Stamping existing DB at Alembic revision 001...")
        alembic_cfg = Config()
        alembic_cfg.set_main_option("script_location", str(alembic_dir))
        alembic_cfg.set_main_option("sqlalchemy.url", str(engine.url))
        command.stamp(alembic_cfg, "001")


def auto_migrate() -> None:
    """Run Alembic migrations if needed.

    Only called by the dedicated init-db container (not by workers).
    Workers depend on init-db completing before they start via
    docker-compose ``service_completed_successfully``.
    """
    try:
        from sqlalchemy import inspect as sa_inspect
        inspector = sa_inspect(engine)
        if not inspector.has_table("models"):
            migrate()
        else:
            # Tables exist — stamp at 001 if created before Alembic was added,
            # then run upgrade to apply any pending migrations (e.g. 002+).
            try:
                _stamp_alembic_if_needed()
                _run_alembic_upgrade()
            except Exception as exc:
                print(f"⚠️  auto_migrate alembic step: {exc}")
    except Exception:
        # First boot or connection issue — try migrate anyway
        try:
            migrate()
        except Exception:
            pass


if __name__ == "__main__":
    import sys

    # Ensure stdout/stderr are line-buffered even when piped (avoids TTY hangs
    # in Docker containers where there is no allocating terminal).
    if hasattr(sys.stdout, "reconfigure"):
        sys.stdout.reconfigure(line_buffering=True)
    if hasattr(sys.stderr, "reconfigure"):
        sys.stderr.reconfigure(line_buffering=True)

    if "--reset" in sys.argv:
        reset_db()
    else:
        migrate()

    # Explicit exit — prevents the process from hanging when run inside
    # ``docker compose run`` without a TTY.
    sys.exit(0)
